Рассмотрены 4 варианта: CPU, CPU + JIT, CUDA + JIT и numpy.dot.

JIT-компиляция ускоряет выполнение Python-кода, преобразуя его в машинный код. Первый запуск JIT-функции требует больше времени из-за компиляции.

Результаты:
При малых размерах матриц (100 и 250) numpy.dot был быстрее всех.
С увеличением размерности CUDA продемонстрировала наибольшее ускорение. Для матриц 1000×1000 она быстрее CPU ~24 раза и CPU JIT ~35 раз.
CPU JIT оказался медленнее CPU из-за накладных расходов.
Особенности:
GPU эффективно распараллеливает умножение матриц, так как элементы результирующей матрицы вычисляются независимо.

Вывод:
Ускорение на GPU объясняется параллелизацией и низкой скоростью Python. Наивная реализация на CPU далека от оптимальной.