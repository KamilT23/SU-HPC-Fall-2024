Было рассмотрено 4 варианта: CPU, CPU + JIT, CUDA + JIT, numpy.sum.
JIT-компиляция позволяет интерпретируемым языкам, таким как Python, динамически переводить части кода в машинный код, что значительно ускоряет выполнение. Библиотека Numba использует этот подход, чтобы ускорить выполнение вашего Python-кода. Она анализирует функцию, определяет типы данных и компилирует её в оптимизированный машинный код. Всё это происходит во время выполнения программы. Когда вы помечаете функцию декоратором @jit, Numba анализирует её, определяет возможные оптимизации, учитывая типы переменных и выполняемые операции, и создаёт высокоэффективный машинный код.
Для замеров времени каждая функция запускалась 12 раз.
Особенностью JIT-компиляции является то, что при первом запуске функция работает дольше из-за этапа компиляции, но последующие вызовы выполняются быстрее.
На GPU каждая нить обрабатывает elements_by_thread элементов, после чего результат добавляется к общей сумме.
На малых размерах данных максимальное ускорение показала функция numpy.sum, особенно при размере вектора 10,000 (ускорение более чем в 18 раз по сравнению с CPU).
При увеличении размера вектора до 100,000 наибольшее преимущество всё ещё оставалось у numpy.sum. Однако на больших массивах (1,000,000 элементов и выше) производительность CPU + JIT оказалась значительно лучше, обеспечив ускорение до 5 раз по сравнению с обычным CPU.
CUDA + JIT подход показал стабильное время выполнения, но не превзошёл numpy.sum при меньших размерах векторов и CPU + JIT на больших данных.